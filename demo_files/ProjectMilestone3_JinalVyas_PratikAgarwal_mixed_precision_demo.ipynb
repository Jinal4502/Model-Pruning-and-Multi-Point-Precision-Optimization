{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B80np2RkpoP_",
        "outputId": "82cc36ae-3ce2-4291-f3d5-69c3db7853be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jjvyas1/jinal_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/Users/jjvyas1/jinal_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.utils.prune as prune\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import time\n",
        "import psutil\n",
        "import os\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "from torchvision.models.resnet import BasicBlock\n",
        "from torch.ao.quantization.fake_quantize import FakeQuantize\n",
        "from torch import Tensor\n",
        "from typing import Any, Callable, List, Optional, Type, Union\n",
        "\n",
        "# 1. Load pretrained ResNet-18\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# 4. Prepare a dummy input\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "img = Image.open(\"/Users/jjvyas1/Downloads/mla_project/n01443537_goldfish.JPEG\").convert(\"RGB\")  # replace with a real image path\n",
        "input_tensor = transform(img).unsqueeze(0)  # batch dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsSplzkQBD-K",
        "outputId": "141b323e-2a03-4b94-bc2a-d0858681ecca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XYnj0cekYXDm"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, device_str='cuda'):\n",
        "    global input_tensor\n",
        "    input_tensor = input_tensor\n",
        "    if not (device_str in['cpu', 'cuda']):\n",
        "        raise NotImplementedError(\"`device_str` should be 'cpu' or 'cuda' \")\n",
        "    if device_str == 'cuda':\n",
        "        assert torch.cuda.is_available(), 'Check CUDA is available'\n",
        "    input_batch = input_tensor.unsqueeze(0)[0]\n",
        "    input_batch = input_batch.to(device_str)\n",
        "    model.to(device_str)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(input_batch)\n",
        "\n",
        "    probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "    with open(\"/Users/jjvyas1/Downloads/mla_project/imagenet_classes.txt\", \"r\") as f:\n",
        "        categories = [s.strip() for s in f.readlines()]\n",
        "    top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
        "    for i in range(top5_prob.size(0)):\n",
        "        print(categories[top5_catid[i]], top5_prob[i].item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LplrKoW7YYOv",
        "outputId": "a706779f-8ae6-43c7-90df-b3563673c3d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "goldfish 0.8217602968215942\n",
            "axolotl 0.14192184805870056\n",
            "tench 0.01749112270772457\n",
            "sturgeon 0.005148489493876696\n",
            "puffer 0.004762660246342421\n"
          ]
        }
      ],
      "source": [
        "evaluate(model, 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "x2GzQ6tRalmR"
      },
      "outputs": [],
      "source": [
        "def get_model_size(model):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    size_mb = os.path.getsize(\"temp.p\") / 1e6\n",
        "    os.remove(\"temp.p\")\n",
        "    print(f\"Model size: {size_mb:.2f} MB\")\n",
        "    return size_mb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4vZKaoJmUUu",
        "outputId": "d1ceadfe-6775-4134-deb1-36c18020d9da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model size: 46.83 MB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "46.828292"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_model_size(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def measure_inference_time(model, input_size=(1, 3, 224, 224), device='cpu', repeats=50):\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(input_size).to(device)\n",
        "    model.to(device)\n",
        "\n",
        "    for _ in range(10):\n",
        "        _ = model(dummy_input)\n",
        "\n",
        "    start = time.time()\n",
        "    for _ in range(repeats):\n",
        "        _ = model(dummy_input)\n",
        "    end = time.time()\n",
        "\n",
        "    avg_time = (end - start) / repeats\n",
        "    print(f\"Inference time (avg over {repeats}): {avg_time*1000:.2f} ms\")\n",
        "    return avg_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference time (avg over 50): 17.49 ms\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.017494516372680666"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "measure_inference_time(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlDBN_Hi0Yo7",
        "outputId": "fd6c6c28-28b0-4edf-e605-10418c23bfbf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu1): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              "  (quant): QuantStub()\n",
              "  (dequant): DeQuantStub()\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "from Downloads.mla_project.resnet import resnet18\n",
        "# loading the quantized model\n",
        "model = resnet18(pretrained=True)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luhzWMjXrWsJ",
        "outputId": "3936f189-8a02-40e3-b388-1ded946d61a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['conv1', 'bn1', 'relu'],\n",
              " ['layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu1'],\n",
              " ['layer1.0.conv2', 'layer1.0.bn2'],\n",
              " ['layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu1'],\n",
              " ['layer1.1.conv2', 'layer1.1.bn2'],\n",
              " ['layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu1'],\n",
              " ['layer2.0.conv2', 'layer2.0.bn2'],\n",
              " ['layer2.0.downsample.0', 'layer2.0.downsample.1'],\n",
              " ['layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu1'],\n",
              " ['layer2.1.conv2', 'layer2.1.bn2'],\n",
              " ['layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu1'],\n",
              " ['layer3.0.conv2', 'layer3.0.bn2'],\n",
              " ['layer3.0.downsample.0', 'layer3.0.downsample.1'],\n",
              " ['layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu1'],\n",
              " ['layer3.1.conv2', 'layer3.1.bn2'],\n",
              " ['layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu1'],\n",
              " ['layer4.0.conv2', 'layer4.0.bn2'],\n",
              " ['layer4.0.downsample.0', 'layer4.0.downsample.1'],\n",
              " ['layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu1'],\n",
              " ['layer4.1.conv2', 'layer4.1.bn2']]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modules_to_list = model.modules_to_fuse()\n",
        "modules_to_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjePJzXFrc2N",
        "outputId": "9ff8bb14-c991-454b-bef2-a16835ac02d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): ConvReLU2d(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "    (1): ReLU(inplace=True)\n",
              "  )\n",
              "  (bn1): Identity()\n",
              "  (relu): Identity()\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU(inplace=True)\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              "  (quant): QuantStub()\n",
              "  (dequant): DeQuantStub()\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()\n",
        "fused_model = torch.ao.quantization.fuse_modules(model, modules_to_list)\n",
        "fused_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wwBw7UYrTfg",
        "outputId": "33a77b4f-887e-4b16-c56f-bf469c34552a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): ConvReLU2d(\n",
              "    3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3)\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "      (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "      (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (bn1): Identity()\n",
              "  (relu): Identity()\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (weight_fake_quant): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "        )\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): Conv2d(\n",
              "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (weight_fake_quant): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "        )\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (weight_fake_quant): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "        )\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): Conv2d(\n",
              "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (weight_fake_quant): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "        )\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
              "        (weight_fake_quant): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "        )\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): Conv2d(\n",
              "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (weight_fake_quant): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "        )\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(\n",
              "          64, 128, kernel_size=(1, 1), stride=(2, 2)\n",
              "          (weight_fake_quant): FakeQuantize(\n",
              "            fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "            (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "          )\n",
              "          (activation_post_process): FakeQuantize(\n",
              "            fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "            (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "        )\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (weight_fake_quant): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "        )\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): Conv2d(\n",
              "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (weight_fake_quant): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "        )\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
              "        (weight_fake_quant): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "        )\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): Conv2d(\n",
              "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (weight_fake_quant): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "        )\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(\n",
              "          128, 256, kernel_size=(1, 1), stride=(2, 2)\n",
              "          (weight_fake_quant): FakeQuantize(\n",
              "            fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "            (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "          )\n",
              "          (activation_post_process): FakeQuantize(\n",
              "            fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "            (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "        )\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (weight_fake_quant): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "        )\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): Conv2d(\n",
              "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (weight_fake_quant): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "        )\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
              "        (weight_fake_quant): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "        )\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): Conv2d(\n",
              "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (weight_fake_quant): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "        )\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(\n",
              "          256, 512, kernel_size=(1, 1), stride=(2, 2)\n",
              "          (weight_fake_quant): FakeQuantize(\n",
              "            fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "            (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "          )\n",
              "          (activation_post_process): FakeQuantize(\n",
              "            fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "            (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "          )\n",
              "        )\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (weight_fake_quant): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "        )\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): Conv2d(\n",
              "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (weight_fake_quant): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "        )\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): FloatFunctional(\n",
              "        (activation_post_process): FakeQuantize(\n",
              "          fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "          (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(\n",
              "    in_features=512, out_features=1000, bias=True\n",
              "    (weight_fake_quant): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, ch_axis=0, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "      (activation_post_process): PerChannelMinMaxObserver(min_val=tensor([]), max_val=tensor([]))\n",
              "    )\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "      (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (quant): QuantStub(\n",
              "    (activation_post_process): FakeQuantize(\n",
              "      fake_quant_enabled=tensor([1], dtype=torch.uint8), observer_enabled=tensor([1], dtype=torch.uint8), quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, ch_axis=-1, scale=tensor([1.]), zero_point=tensor([0], dtype=torch.int32)\n",
              "      (activation_post_process): HistogramObserver(min_val=inf, max_val=-inf)\n",
              "    )\n",
              "  )\n",
              "  (dequant): DeQuantStub()\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.ao.quantization.fake_quantize import FakeQuantize\n",
        "activation_qconfig = FakeQuantize.with_args(\n",
        "    observer=torch.ao.quantization.observer.HistogramObserver.with_args(\n",
        "        quant_min=0,\n",
        "        quant_max=255,\n",
        "        dtype=torch.quint8,\n",
        "        qscheme=torch.per_tensor_affine,\n",
        "    )\n",
        ")\n",
        "\n",
        "weight_qconfig = FakeQuantize.with_args(\n",
        "    observer=torch.ao.quantization.observer.PerChannelMinMaxObserver.with_args(\n",
        "        quant_min=-128,\n",
        "        quant_max=127,\n",
        "        dtype=torch.qint8,\n",
        "        qscheme=torch.per_channel_symmetric,\n",
        "    )\n",
        ")\n",
        "\n",
        "qconfig = torch.quantization.QConfig(activation=activation_qconfig,\n",
        "                                      weight=weight_qconfig)\n",
        "fused_model.qconfig = qconfig\n",
        "\n",
        "fused_model.train()\n",
        "fake_quant_model = torch.ao.quantization.prepare_qat(fused_model)\n",
        "fake_quant_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YguvooU2rl7n",
        "outputId": "379f2bbf-5085-434c-8fd1-daed6c501742"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fake quant - PTQ\n",
            "goldfish 0.8090365529060364\n",
            "axolotl 0.13504262268543243\n",
            "tench 0.022541021928191185\n",
            "sturgeon 0.00920926034450531\n",
            "puffer 0.0070404428988695145\n",
            "\n",
            "Fake quant - post-PTQ\n",
            "goldfish 0.8090365529060364\n",
            "axolotl 0.13504262268543243\n",
            "tench 0.022541021928191185\n",
            "sturgeon 0.00920926034450531\n",
            "puffer 0.0070404428988695145\n",
            "\n",
            "Converted model\n",
            "goldfish 0.7802646160125732\n",
            "axolotl 0.15577368438243866\n",
            "tench 0.026001403108239174\n",
            "sturgeon 0.011617783457040787\n",
            "puffer 0.006790062412619591\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nFake quant - PTQ\")\n",
        "evaluate(fake_quant_model, 'cpu')\n",
        "\n",
        "fake_quant_model.apply(torch.ao.quantization.fake_quantize.disable_observer)\n",
        "\n",
        "print(\"\\nFake quant - post-PTQ\")\n",
        "evaluate(fake_quant_model, 'cpu')\n",
        "\n",
        "\n",
        "# Step 5: convert (true int8 model)\n",
        "torch.backends.quantized.engine = 'qnnpack'\n",
        "converted_model = torch.ao.quantization.convert(fake_quant_model)\n",
        "\n",
        "print(\"\\nConverted model\")\n",
        "evaluate(converted_model, 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.00305533641949296, zero_point=0, padding=(3, 3))\n",
              "  (bn1): Identity()\n",
              "  (relu): Identity()\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.002219036454334855, zero_point=0, padding=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.013336235657334328, zero_point=127, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): QFunctional(\n",
              "        scale=0.007735367398709059, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.004394977353513241, zero_point=0, padding=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.015967005863785744, zero_point=144, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): QFunctional(\n",
              "        scale=0.011056358925998211, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.005023206118494272, zero_point=0, padding=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.017707210034132004, zero_point=90, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.00866786204278469, zero_point=112)\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (add_relu_FF): QFunctional(\n",
              "        scale=0.009186672046780586, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.005754124838858843, zero_point=0, padding=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.016820408403873444, zero_point=135, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): QFunctional(\n",
              "        scale=0.012269865721464157, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.00758524751290679, zero_point=0, padding=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.021688444539904594, zero_point=83, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.00595097616314888, zero_point=180)\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (add_relu_FF): QFunctional(\n",
              "        scale=0.01135631836950779, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.005394933745265007, zero_point=0, padding=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.016411039978265762, zero_point=152, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): QFunctional(\n",
              "        scale=0.007974398322403431, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.003923657350242138, zero_point=0, padding=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.01950124464929104, zero_point=121, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.01462660450488329, zero_point=124)\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (add_relu_FF): QFunctional(\n",
              "        scale=0.0117914117872715, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.005488987546414137, zero_point=0, padding=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.10926572233438492, zero_point=84, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): QFunctional(\n",
              "        scale=0.07688441872596741, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): QuantizedLinear(in_features=512, out_features=1000, scale=0.08951269090175629, zero_point=84, qscheme=torch.per_channel_affine)\n",
              "  (quant): Quantize(scale=tensor([0.0038]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "  (dequant): DeQuantize()\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "converted_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class CustomDeQuantize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.dequantize() if x.is_quantized else x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 1: Extract quantized FC layer and get its dequantized weight & bias\n",
        "quant_fc = converted_model.fc\n",
        "qweight, bias = quant_fc._weight_bias()\n",
        "\n",
        "# Step 2: Dequantize the weights\n",
        "dequant_weight = qweight.dequantize()\n",
        "dequant_bias = bias\n",
        "\n",
        "# Step 3: Replace QuantizedLinear with nn.Linear (float32)\n",
        "fc_fp32 = nn.Linear(in_features=quant_fc.in_features,\n",
        "                    out_features=quant_fc.out_features)\n",
        "\n",
        "# Step 4: Assign dequantized weights and bias\n",
        "fc_fp32.weight.data = dequant_weight\n",
        "fc_fp32.bias.data = dequant_bias\n",
        "\n",
        "# Step 5: Put it back into the model\n",
        "# converted_model.fc = fc_fp32\n",
        "converted_model.fc = nn.Sequential(\n",
        "    CustomDeQuantize(),  # Manually defined\n",
        "    fc_fp32\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.00305533641949296, zero_point=0, padding=(3, 3))\n",
              "  (bn1): Identity()\n",
              "  (relu): Identity()\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.002219036454334855, zero_point=0, padding=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.013336235657334328, zero_point=127, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): QFunctional(\n",
              "        scale=0.007735367398709059, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.004394977353513241, zero_point=0, padding=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.015967005863785744, zero_point=144, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): QFunctional(\n",
              "        scale=0.011056358925998211, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.005023206118494272, zero_point=0, padding=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.017707210034132004, zero_point=90, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), scale=0.00866786204278469, zero_point=112)\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (add_relu_FF): QFunctional(\n",
              "        scale=0.009186672046780586, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.005754124838858843, zero_point=0, padding=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.016820408403873444, zero_point=135, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): QFunctional(\n",
              "        scale=0.012269865721464157, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.00758524751290679, zero_point=0, padding=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.021688444539904594, zero_point=83, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), scale=0.00595097616314888, zero_point=180)\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (add_relu_FF): QFunctional(\n",
              "        scale=0.01135631836950779, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.005394933745265007, zero_point=0, padding=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.016411039978265762, zero_point=152, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): QFunctional(\n",
              "        scale=0.007974398322403431, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.003923657350242138, zero_point=0, padding=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.01950124464929104, zero_point=121, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), scale=0.01462660450488329, zero_point=124)\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (add_relu_FF): QFunctional(\n",
              "        scale=0.0117914117872715, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.005488987546414137, zero_point=0, padding=(1, 1))\n",
              "      (bn1): Identity()\n",
              "      (relu1): Identity()\n",
              "      (conv2): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.10926572233438492, zero_point=84, padding=(1, 1))\n",
              "      (bn2): Identity()\n",
              "      (add_relu_FF): QFunctional(\n",
              "        scale=0.07688441872596741, zero_point=0\n",
              "        (activation_post_process): Identity()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Sequential(\n",
              "    (0): CustomDeQuantize()\n",
              "    (1): Linear(in_features=512, out_features=1000, bias=True)\n",
              "  )\n",
              "  (quant): Quantize(scale=tensor([0.0038]), zero_point=tensor([0]), dtype=torch.quint8)\n",
              "  (dequant): DeQuantize()\n",
              ")"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "converted_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CpaS6IUax6K",
        "outputId": "022dbf6c-f337-488a-a3b6-de4fba04f479"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model size: 13.35 MB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "13.353194"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_model_size(converted_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference time (avg over 50): 14.68 ms\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.014678578376770019"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "measure_inference_time(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for name, module in converted_model.named_modules():\n",
        "    if name == \"fc\":\n",
        "        weights = converted_model.fc[1].weight.detach().flatten().numpy()\n",
        "        plt.hist(weights, bins=15)\n",
        "        plt.title(f\"Histogram of Weights in {name}\")\n",
        "        plt.xlabel(\"Weight value\")\n",
        "        plt.ylabel(\"Frequency\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oHP2bnCxYruv"
      },
      "outputs": [],
      "source": [
        "def custom_abs(flattened_weights, zero_point, scale):\n",
        "  # Dequantize the weights\n",
        "  dequantized_weights = scale * (flattened_weights.dequantize() - zero_point)\n",
        "\n",
        "  # Calculate the absolute values\n",
        "  absolute_flattened_weights = torch.abs(dequantized_weights)\n",
        "  quantized_absolute_weights = torch.quantize_per_tensor(\n",
        "    absolute_flattened_weights, scale, zero_point, torch.qint8)\n",
        "\n",
        "  return quantized_absolute_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ4ZYG_T6l26",
        "outputId": "219ef070-b095-4c6b-b010-7d02343cf5cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QuantizedConvReLU2d(3, 64, kernel_size=(7, 7), stride=(2, 2), scale=0.00305533641949296, zero_point=0, padding=(3, 3))\n",
            "QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.002219036454334855, zero_point=0, padding=(1, 1))\n",
            "QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.013336235657334328, zero_point=127, padding=(1, 1))\n",
            "QuantizedConvReLU2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.004394977353513241, zero_point=0, padding=(1, 1))\n",
            "QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=0.015967005863785744, zero_point=144, padding=(1, 1))\n",
            "QuantizedConvReLU2d(64, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.005023206118494272, zero_point=0, padding=(1, 1))\n",
            "QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.017707210034132004, zero_point=90, padding=(1, 1))\n",
            "QuantizedConvReLU2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.005754124838858843, zero_point=0, padding=(1, 1))\n",
            "QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.016820408403873444, zero_point=135, padding=(1, 1))\n",
            "QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.00758524751290679, zero_point=0, padding=(1, 1))\n",
            "QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.021688444539904594, zero_point=83, padding=(1, 1))\n",
            "QuantizedConvReLU2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.005394933745265007, zero_point=0, padding=(1, 1))\n",
            "QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.016411039978265762, zero_point=152, padding=(1, 1))\n",
            "QuantizedConvReLU2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.003923657350242138, zero_point=0, padding=(1, 1))\n",
            "QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.01950124464929104, zero_point=121, padding=(1, 1))\n",
            "QuantizedConvReLU2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.005488987546414137, zero_point=0, padding=(1, 1))\n",
            "QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.10926572233438492, zero_point=84, padding=(1, 1))\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.utils.prune as prune\n",
        "import numpy as np\n",
        "\n",
        "for name, module in converted_model.named_modules():\n",
        "  if \"conv1\" in name or \"conv2\" in name:\n",
        "    print(module)\n",
        "    weight = module.weight()\n",
        "    scale = module.scale\n",
        "    zero_point = module.zero_point\n",
        "\n",
        "    # Perform pruning: Setting a fraction of weights to zero (e.g., 30%)\n",
        "    pruning_amount = 0.3\n",
        "    num_weights = weight.numel()\n",
        "    num_pruned_weights = int(pruning_amount * num_weights)\n",
        "\n",
        "    # Flatten the weights, sort by absolute value, and zero out the smallest\n",
        "    zero_point = max(min(zero_point, 127), -128)\n",
        "    weight = custom_abs(weight, zero_point, scale)\n",
        "    flattened_weights = weight.reshape(-1)\n",
        "    sorted_indices = torch.argsort(flattened_weights)\n",
        "\n",
        "    # # Prune the smallest weights\n",
        "    pruned_weights = flattened_weights.clone()\n",
        "    pruned_weights[sorted_indices[:num_pruned_weights]] = 0\n",
        "\n",
        "    # # Reshape pruned weights back to the original shape\n",
        "    pruned_weights = pruned_weights.view_as(weight)\n",
        "\n",
        "    # print(module.weight())\n",
        "    # print(module.bias())\n",
        "    bias = module.bias()\n",
        "    module.set_weight_bias(pruned_weights, bias)\n",
        "\n",
        "  if \"fc\" in name and isinstance(module, nn.Sequential):\n",
        "    if isinstance(module[1], nn.Linear):\n",
        "      prune.l1_unstructured(module[1], name=\"weight\", amount=0.1)\n",
        "      prune.remove(module[1], \"weight\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "4uixqK-MZE5p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model size: 13.28 MB\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "13.284244"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_model_size(converted_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inference time (avg over 50): 15.42 ms\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.015416641235351563"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "measure_inference_time(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "washer 0.6157040596008301\n",
            "syringe 0.3833581209182739\n",
            "barrow 0.0004479032359085977\n",
            "bucket 0.00015850670752115548\n",
            "ashcan 7.864601502660662e-05\n"
          ]
        }
      ],
      "source": [
        "evaluate(converted_model, 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "conv1\n",
            "bn1\n",
            "relu\n",
            "maxpool\n",
            "layer1\n",
            "layer1.0\n",
            "layer1.0.conv1\n",
            "layer1.0.bn1\n",
            "layer1.0.relu1\n",
            "layer1.0.conv2\n",
            "layer1.0.bn2\n",
            "layer1.0.add_relu_FF\n",
            "layer1.0.add_relu_FF.activation_post_process\n",
            "layer1.1\n",
            "layer1.1.conv1\n",
            "layer1.1.bn1\n",
            "layer1.1.relu1\n",
            "layer1.1.conv2\n",
            "layer1.1.bn2\n",
            "layer1.1.add_relu_FF\n",
            "layer1.1.add_relu_FF.activation_post_process\n",
            "layer2\n",
            "layer2.0\n",
            "layer2.0.conv1\n",
            "layer2.0.bn1\n",
            "layer2.0.relu1\n",
            "layer2.0.conv2\n",
            "layer2.0.bn2\n",
            "layer2.0.downsample\n",
            "layer2.0.downsample.0\n",
            "layer2.0.downsample.1\n",
            "layer2.0.add_relu_FF\n",
            "layer2.0.add_relu_FF.activation_post_process\n",
            "layer2.1\n",
            "layer2.1.conv1\n",
            "layer2.1.bn1\n",
            "layer2.1.relu1\n",
            "layer2.1.conv2\n",
            "layer2.1.bn2\n",
            "layer2.1.add_relu_FF\n",
            "layer2.1.add_relu_FF.activation_post_process\n",
            "layer3\n",
            "layer3.0\n",
            "layer3.0.conv1\n",
            "layer3.0.bn1\n",
            "layer3.0.relu1\n",
            "layer3.0.conv2\n",
            "layer3.0.bn2\n",
            "layer3.0.downsample\n",
            "layer3.0.downsample.0\n",
            "layer3.0.downsample.1\n",
            "layer3.0.add_relu_FF\n",
            "layer3.0.add_relu_FF.activation_post_process\n",
            "layer3.1\n",
            "layer3.1.conv1\n",
            "layer3.1.bn1\n",
            "layer3.1.relu1\n",
            "layer3.1.conv2\n",
            "layer3.1.bn2\n",
            "layer3.1.add_relu_FF\n",
            "layer3.1.add_relu_FF.activation_post_process\n",
            "layer4\n",
            "layer4.0\n",
            "layer4.0.conv1\n",
            "layer4.0.bn1\n",
            "layer4.0.relu1\n",
            "layer4.0.conv2\n",
            "layer4.0.bn2\n",
            "layer4.0.downsample\n",
            "layer4.0.downsample.0\n",
            "layer4.0.downsample.1\n",
            "layer4.0.add_relu_FF\n",
            "layer4.0.add_relu_FF.activation_post_process\n",
            "layer4.1\n",
            "layer4.1.conv1\n",
            "layer4.1.bn1\n",
            "layer4.1.relu1\n",
            "layer4.1.conv2\n",
            "layer4.1.bn2\n",
            "layer4.1.add_relu_FF\n",
            "layer4.1.add_relu_FF.activation_post_process\n",
            "avgpool\n",
            "fc\n",
            "fc.0\n",
            "fc.1\n",
            "quant\n",
            "dequant\n"
          ]
        }
      ],
      "source": [
        "for name, module in converted_model.named_modules():\n",
        "  print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for name, module in converted_model.named_modules():\n",
        "    if name == \"fc\":\n",
        "        weights = converted_model.fc[1].weight.detach().flatten().numpy()\n",
        "        plt.hist(weights, bins=2)\n",
        "        plt.title(f\"Histogram of Weights in {name}\")\n",
        "        plt.xlabel(\"Weight value\")\n",
        "        plt.ylabel(\"Frequency\")\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
